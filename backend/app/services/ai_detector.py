#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ai_detector.py
~~~~~~~~~~~~~~

Lightweight wrapper around the open-source model
`roberta-base-openai-detector` to estimate the probability that a text
snippet was machine-generated.

----------------------------------------------------------------------
Quick CLI usage
----------------------------------------------------------------------

$ python ai_detector.py "Large Language Models are ..."
AI-likelihood: 87.3 %

----------------------------------------------------------------------
Embedding in code
----------------------------------------------------------------------

>>> from ai_detector import detect_ai_content
>>> detect_ai_content("Hello, world!")
0.12   # ↦ 12 % chance text is AI-generated

----------------------------------------------------------------------
Dependencies
----------------------------------------------------------------------
- transformers (≥ 4.51)          # already in requirements.txt
- torch (≥ 2.3)                  # already in requirements.txt
- sentencepiece                  # already in requirements.txt
"""

from __future__ import annotations

import argparse
import sys
from typing import Final

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

_MODEL_NAME: Final = "roberta-base-openai-detector"

tokenizer = AutoTokenizer.from_pretrained(_MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(_MODEL_NAME)


def detect_ai_content(text: str) -> float:
    """
    Return the probability (0–1) that *text* was generated by an LLM.

    The underlying classifier outputs ``[P(human), P(machine)]``; we
    return ``P(machine)`` as a float.
    """
    inputs = tokenizer(text, return_tensors="pt",
                       truncation=True, max_length=512)
    with torch.no_grad():
        logits = model(**inputs).logits
    return torch.softmax(logits, dim=1)[0, 1].item()


# ------------------------------------------------------------------ #
# CLI interface                                                      #
# ------------------------------------------------------------------ #
def _cli() -> None:
    parser = argparse.ArgumentParser(
        description="Estimate AI-likelihood of text.")
    parser.add_argument(
        "text", help="Raw text to analyse (surround with quotes).")
    args = parser.parse_args()

    score = detect_ai_content(args.text)
    print(f"AI-likelihood: {score:.1%}")


if __name__ == "__main__":
    _cli()
